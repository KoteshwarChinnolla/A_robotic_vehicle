## Functionalities of the Vehicle
> 1. Understanding Natural language
> 2. Transforming things from one place to another
> 3. Responding to User inputs
> 4. asks task-specific questions
> 5. performing complex and lengthy workflows flawlessly

## Understanding Natural language

This is a crucial step in the generation of workflow plans and responses.
We use LLMs with tool-calling features to understand the user response accurately and make plans accordingly. We make use of LLM in different ways
> 1. Tool-calling LLM (for Generation of task-specific workflows)
> 2. Input Classification LLM ( for classifying whether the user is asking to perform a Task or the user question refers to a general response like the current position of the vehicle or history of tasks it has performed till now or any functionality related)
> 3. Orchestrator (For making user Input a bit more constructed to make perfect plans)
> 4. Responding LLM ( for responding to the input message given by user. It doesn't refer to location-specific messages)

## Transferring things from one place to another

Here we use a combination of the A* algorithm and decoder.

**A* algorithm** - It is a path-finding algorithm. it is highly accurate in finding the shortest path  between 2 nodes in graph-based environments. In our case, we consider our image as a graph where obstacles are represented by 1s and free paths are represented by 0. We make use of the A* algorithm to find the shortest path between the nodes given by the user(through LLMs)

**Decoder** - The decoder is specifically used to make the outputs generated by the A* algorithm in a way that can be instructed to Arduino so that the vehicle follows that specific path accurately without any directionality errors.

## Responding to user Inputs

There are 3 major reasons for implementing this functionality. 

> 1. What if the vehicle is performing another task while the user requests his task?
> 2. What if there is no such location in the house or industry environment?
> 3. What if the user wants to clarify things like (where it is currently or the history of tasks it has performed till now or any functionality related) rather then making it to perform the task?

In every case, the user question is redirected to Responding LLM. so that it process user input and generate responses accordingly.

## Asks Task Specific questions

currently, the vehicle itself doesn't perform tasks by itself it takes the help of Humans.

The functionality of the vehicle is to Travel, transport and speak. so every time it is performing tasks if the vehicle can't do it by itself it asks for someone who help it out in performing that task.

To make you understand let us consider an example - if the user asks to bring some coffee from the kitchen to the bedroom.  so it first reaches the kitchen and asks for someone who makes the coffee. it weighs until the coffee is done making. then it comes back to the bedroom with the coffee.

## Performing complex and lengthy workflows flawlessly.

**Complex? What complex over here? it is just travelling from one place to another place..** you may get dought like this but I want you to imagene some cases>

> *Case 1.*  **task in task** (tasks are dependent). if it needed to complete some task which is part of its original task.
> 
> for better understanding let's have an example - same as the previous if someone wants coffee from the kitchen to bedroom . As the vehicle reaches the kitchen when it asks to make coffee, what if the user says that **there is no coffee powder go to the storeroom and bring it back to the kitchen**.
> 
> In this case it has to perform task in task. where it has to make a plan to go to the store room and bring the coffee powder back, then it needs to travel to the bedroom with the coffee as the coffee making is done.
> 
> For implementation I used the concept of **Backtracking**

> *case 2* **Task After Task** (tasks are independent): When should Task 2 be completed if it is instructed to start while Task 1 is still in progress?
>
> example: if the vehicle is in the process of bringing coffee to the bedroom if someone instructs it to get the bat from the storeroom to the park. as the tasks are not related to each other it needs to serialise them. one after the other.
>
> to make this happen I used the concept of serialisation.


# To run it on your local system

> **Step 1** : Install docker on your system
> 
> **Step 2** : Clone this repo by using
```python
git clone https://github.com/KoteshwarChinnolla/A_robotic_vehicle
```
> **Step 3**: " create .env file put Langchain and Groq API key
```python
LANG_CHAIN_API_KEY=""
GROQ_API_KEY=""
```
> **Step 4**: open the docker desktop so that it turns on the docker Engine
> **Step 5**:run
```python
docker compose up --build
```
> on your terminal
> 
> Now run the HTML file (Go live) so that you can access it




