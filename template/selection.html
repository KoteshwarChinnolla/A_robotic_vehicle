<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Image Selector</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    
    <dev id="selectImage"><h1>Image Selector</h1>
    <button onclick="openPopup()">Select Image</button></dev>
    <p id="selectedText">No image selected</p>
    <img class="selected-image" id="selectedImage" src="" alt="">
    <button id="proceedBtn" onclick="proceed()" >Proceed</button>
    
    <div id="popup" class="popup">
        <h2>Select an Image</h2>
        <div class="grid" id="imageGrid"></div>
        <button onclick="closePopup()">Close</button>
    </div>
    
    <div id="chatInput" class="chat-container">
        <form onsubmit="sendMessage(event); return false;">
            <div class="chat-input" onclick="expandInput()">
                <input type="text" id="user-input" placeholder="Type your message..." onblur="shrinkInput()">
                <button type="submit">Send</button>
                <button type="button" id="mic-button" onclick="startVoiceInput()">
                    üéôÔ∏è
                </button>
            </div>
        </form>
    </div>
    <div id="chatInput_2" class="chat-container">
        <div class="chat-input" onclick="expandInput()">
            <input type="text" id="userInput" placeholder="Type something..." onblur="shrinkInput()">
            <button onclick="resolveInput()">Submit</button>
            <button id="micButton">üéôÔ∏è</button>
        </div>
    </div>
    <div class="out-put-test" id="out-put-test"></div>
    <div class="canvas">
    <canvas id="mazeCanvas" width="256" height="256"></canvas>
    </div>
    <div class="container" id="container">
        <h1>Functionalities of the Vehicle</h2>

        <blockquote>
          <ol>
          <li>Understanding Natural language</li>
          <li>Transforming things from one place to another</li>
          <li>Responding to User inputs</li>
          <li>asks task-specific questions</li>
          <li>performing complex and lengthy workflows flawlessly</li>
          </ol>
        </blockquote>
        
        <h2>Understanding Natural language</h2>
        
        <p>This is a crucial step in the generation of workflow plans and responses.
        We use LLMs with tool-calling features to understand the user response accurately and make plans accordingly. We make use of LLM in different ways</p>
        
        <blockquote>
          <ol>
          <li>Tool-calling LLM (for Generation of task-specific workflows)</li>
          <li>Input Classification LLM ( for classifying whether the user is asking to perform a Task or the user question refers to a general response like the current position of the vehicle or history of tasks it has performed till now or any functionality related)</li>
          <li>Orchestrator (For making user Input a bit more constructed to make perfect plans)</li>
          <li>Responding LLM ( for responding to the input message given by user. It doesn't refer to location-specific messages)</li>
          </ol>
        </blockquote>
        
        <h2>Transferring things from one place to another</h2>
        
        <p>Here we use a combination of the A* algorithm and decoder.</p>
        
        <p><strong>A* algorithm</strong> - It is a path-finding algorithm. it is highly accurate in finding the shortest path  between 2 nodes in graph-based environments. In our case, we consider our image as a graph where obstacles are represented by 1s and free paths are represented by 0. We make use of the A* algorithm to find the shortest path between the nodes given by the user(through LLMs)</p>
        
        <p><strong>Decoder</strong> - The decoder is specifically used to make the outputs generated by the A* algorithm in a way that can be instructed to Arduino so that the vehicle follows that specific path accurately without any directionality errors.</p>
        
        <h2>Responding to user Inputs</h2>
        
        <p>There are 3 major reasons for implementing this functionality. </p>
        
        <blockquote>
          <ol>
          <li>What if the vehicle is performing another task while the user requests his task?</li>
          <li>What if there is no such location in the house or industry environment?</li>
          <li>What if the user wants to clarify things like (where it is currently or the history of tasks it has performed till now or any functionality related) rather then making it to perform the task?</li>
          </ol>
        </blockquote>
        
        <p>In every case, the user question is redirected to Responding LLM. so that it process user input and generate responses accordingly.</p>
        
        <h2>Asks Task Specific questions</h2>
        
        <p>currently, the vehicle itself doesn't perform tasks by itself it takes the help of Humans.</p>
        
        <p>The functionality of the vehicle is to Travel, transport and speak. so every time it is performing tasks if the vehicle can't do it by itself it asks for someone who help it out in performing that task.</p>
        
        <p>To make you understand let us consider an example - if the user asks to bring some coffee from the kitchen to the bedroom.  so it first reaches the kitchen and asks for someone who makes the coffee. it weighs until the coffee is done making. then it comes back to the bedroom with the coffee.</p>
        
        <h2>Performing complex and lengthy workflows flawlessly.</h2>
        
        <p><strong>Complex? What complex over here? it is just travelling from one place to another place..</strong> you may get dought like this but I want you to imagene some cases></p>
        
        <blockquote>
          <h3><em>Case 1.</em></h3>
          
          <p><strong>task in task</strong> (tasks are dependent). if it needed to complete some task which is part of its original task.</p>
          
          <p>for better understanding let's have an example - same as the previous if someone wants coffee from the kitchen to bedroom . As the vehicle reaches the kitchen when it asks to make coffee, what if the user says that <strong>there is no coffee powder go to the storeroom and bring it back to the kitchen</strong>.</p>
          
          <p>In this case it has to perform task in task. where it has to make a plan to go to the store room and bring the coffee powder back, then it needs to travel to the bedroom with the coffee as the coffee making is done.</p>
          
          <p>For implementation I used the concept of <strong>Backtracking</strong></p>
        </blockquote>
        
        <blockquote>
          <h3><em>case 2</em></h3>
          
          <p><strong>Task After Task</strong> (tasks are independent): When should Task 2 be completed if it is instructed to start while Task 1 is still in progress?</p>
          
          <p>example: if the vehicle is in the process of bringing coffee to the bedroom if someone instructs it to get the bat from the storeroom to the park. as the tasks are not related to each other it needs to serialise them. one after the other.</p>
          
          <p>to make this happen I used the concept of serialisation.</p>
        </blockquote>
        
        <h1>To run it on your local system</h1>
        
        <blockquote>
          <p><strong>Step 1</strong> : Install docker on your system</p>
          
          <p><strong>Step 2</strong> : Clone this repo by using
          <code>python
        git clone https://github.com/KoteshwarChinnolla/A_robotic_vehicle
        </code>
          <strong>Step 3</strong>: " create .env file put Langchain and Groq API key
          <code>python
        LANG_CHAIN_API_KEY=""
        GROQ_API_KEY=""
        </code>
          <strong>Step 4</strong>: open the docker desktop so that it turns on the docker Engine</p>
          
          <p><strong>Step 5</strong>:run
          <code>python
        docker compose up --build
        </code>
          on your terminal</p>
          
          <p>Now run the HTML file (Go live) so that you can access it</p>
        </blockquote>        
    </div>
    <!-- <div class="controls">
        <button onclick="resetMaze()">Reset</button>
    </div> -->

    <script src="images_select.js"></script>
</body>
</html>
